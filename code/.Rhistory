new_data_seed_size_no_slope <- data.frame(tree_height = mean(data$tree_height), slope = "Not Steep", seed_size = seq(min(data$seed_size), max(data$seed_size), length.out = 100))
predicted_values_seed_size_no_slope <- predict(model, newdata = new_data_seed_size_no_slope, se.fit = TRUE)
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit, col = "blue", lwd=1.5)
# Add the lines for standard errors (confidence intervals) in blue
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit - 1.96 * predicted_values_seed_size_no_slope$se.fit, col = "blue", lty = 2)
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit + 1.96 * predicted_values_seed_size_no_slope$se.fit, col = "blue", lty = 2)
legend("topright", legend = c("Steep", "Not Steep"), col= c("red", "blue"), lty = 1)
# Scatterplot for tree height
plot(data$tree_height, data$dispersal_distance,
main = "Tree Height vs. Dispersal Distance",
xlab = "Tree Height (m)",
ylab = "Dispersal Distance (m)",
pch = 16, col = "gray")
# Create new data with fixed values for seed_size (mean) and slope (Steep)
new_data_tree_height <- data.frame(tree_height = seq(min(data$tree_height), max(data$tree_height), length.out = 100), slope = "Steep", seed_size = mean(data$seed_size))
predicted_values_tree_height <- predict(model, newdata = new_data_tree_height, se.fit = TRUE)
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit, col = "red", lwd =1.5)
# Add the lines for standard errors (confidence intervals) in red
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit - 1.96 * predicted_values_tree_height$se.fit, col = "red", lty = 2)
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit + 1.96 * predicted_values_tree_height$se.fit, col = "red", lty = 2)
# Create new data with fixed values for tree_height (mean) and slope (Not Steep)
new_data_tree_height_no_slope <- data.frame(tree_height = seq(min(data$tree_height), max(data$tree_height), length.out = 100), slope = "Not Steep", seed_size = mean(data$seed_size))
predicted_values_tree_height_no_slope <- predict(model, newdata = new_data_tree_height_no_slope, se.fit = TRUE)
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit, col = "blue", lwd=1.5)
# Add the lines for standard errors (confidence intervals) in blue
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit - 1.96 * predicted_values_tree_height_no_slope$se.fit, col = "blue", lty = 2)
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit + 1.96 * predicted_values_tree_height_no_slope$se.fit, col = "blue", lty = 2)
legend("topright", legend = c("Steep", "Not Steep"), col= c("red", "blue"), lty = 1)
# Scatterplot for seed size
plot(data$seed_size, data$dispersal_distance,
main = "Seed Size vs. Dispersal Distance",
xlab = "Seed Size (mm)",
ylab = "Dispersal Distance (m)",
pch = 16, col = "gray")
# Create new data with fixed values for tree_height (mean) and slope (Slope)
new_data_seed_size <- data.frame(tree_height = mean(data$tree_height), slope = "Steep", seed_size = seq(min(data$seed_size), max(data$seed_size), length.out = 100))
# We use the model to predict to this new data set.
# Need to specify the new data set as newdata.
# se.fit TRUE will return the error of the predicted mean.
predicted_values_seed_size <- predict(model, newdata = new_data_seed_size, se.fit = TRUE)
lines(new_data_seed_size$seed_size, predicted_values_seed_size$fit, col = "red", lwd =1.5)
# Add the lines for standard errors (confidence intervals) in red. 1.96*standard deviation is normal approximation of Confidence interval.
lines(new_data_seed_size$seed_size, predicted_values_seed_size$fit - 1.96 * predicted_values_seed_size$se.fit, col = "red", lty = 2)
lines(new_data_seed_size$seed_size, predicted_values_seed_size$fit + 1.96 * predicted_values_seed_size$se.fit, col = "red", lty = 2)
# Create new data with fixed values for tree_height (mean) and slope (Not Steep)
new_data_seed_size_no_slope <- data.frame(tree_height = mean(data$tree_height), slope = "Not Steep", seed_size = seq(min(data$seed_size), max(data$seed_size), length.out = 100))
predicted_values_seed_size_no_slope <- predict(model, newdata = new_data_seed_size_no_slope, se.fit = TRUE)
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit, col = "blue", lwd=1.5)
# Add the lines for standard errors (confidence intervals) in blue
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit - 1.96 * predicted_values_seed_size_no_slope$se.fit, col = "blue", lty = 2)
lines(new_data_seed_size_no_slope$seed_size, predicted_values_seed_size_no_slope$fit + 1.96 * predicted_values_seed_size_no_slope$se.fit, col = "blue", lty = 2)
legend("topright", legend = c("Steep", "Not Steep"), col= c("red", "blue"), lty = 1)
# Scatterplot for tree height
plot(data$tree_height, data$dispersal_distance,
main = "Tree Height vs. Dispersal Distance",
xlab = "Tree Height (m)",
ylab = "Dispersal Distance (m)",
pch = 16, col = "gray")
# Create new data with fixed values for seed_size (mean) and slope (Steep)
new_data_tree_height <- data.frame(tree_height = seq(min(data$tree_height), max(data$tree_height), length.out = 100), slope = "Steep", seed_size = mean(data$seed_size))
predicted_values_tree_height <- predict(model, newdata = new_data_tree_height, se.fit = TRUE)
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit, col = "red", lwd =1.5)
# Add the lines for standard errors (confidence intervals) in red
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit - 1.96 * predicted_values_tree_height$se.fit, col = "red", lty = 2)
lines(new_data_tree_height$tree_height, predicted_values_tree_height$fit + 1.96 * predicted_values_tree_height$se.fit, col = "red", lty = 2)
# Create new data with fixed values for tree_height (mean) and slope (Not Steep)
new_data_tree_height_no_slope <- data.frame(tree_height = seq(min(data$tree_height), max(data$tree_height), length.out = 100), slope = "Not Steep", seed_size = mean(data$seed_size))
predicted_values_tree_height_no_slope <- predict(model, newdata = new_data_tree_height_no_slope, se.fit = TRUE)
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit, col = "blue", lwd=1.5)
# Add the lines for standard errors (confidence intervals) in blue
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit - 1.96 * predicted_values_tree_height_no_slope$se.fit, col = "blue", lty = 2)
lines(new_data_tree_height_no_slope$tree_height, predicted_values_tree_height_no_slope$fit + 1.96 * predicted_values_tree_height_no_slope$se.fit, col = "blue", lty = 2)
legend("topright", legend = c("Steep", "Not Steep"), col= c("red", "blue"), lty = 1)
sample_sizes <- c(runif(10, 250, 500))
mean_temperature <- runif(10, 3, 15)
mean_temperature <- sort(runif(10, 3, 15))
mean_precipitation <- runif(10, 0, 200)
linear_predictor <- 1 - 0.3* mean_temperature - 0.4*mean_precipitation
plogis(linear_predictor)
counts <- round(runif(10, min = 0, max = sample_sizes))
counts2 <- rbinom(samples, sample_sizes, 0.3)
samples <-  10
counts2 <- rbinom(samples, sample_sizes, 0.3)
sample_sizes
sample_sizes <- floor(runif(samples, 250, 500))
counts2 <- rbinom(samples, sample_sizes, 0.3)
cat(counts1)
counts1 <- round(runif(samples, min = 0, max = sample_sizes))
cat(counts2)
cat(counts1)
df <- data.frame(sample_sizes = sample_sizes,
mean_temperature =mean_temperature,
mean_precipitation = mean_precipitation )
df$mean_precipitation_scaled = scale(df$mean_precipitation)
set.seed(13)
samples <-  10
mean_temperature <- sort(runif(10, 3, 15))
mean_precipitation <- runif(samples, 0, 200)
sample_sizes <- floor(runif(samples, 250, 500))
df <- data.frame(sample_sizes = sample_sizes,
mean_temperature =mean_temperature,
mean_precipitation = mean_precipitation )
df$mean_temperature_scaled = scale(df$mean_temperature)
df$mean_precipitation_scaled = scale(df$mean_precipitation)
linear_predictor <- 1 - 0.1 *df$mean_precipitation_scaled - 0.2*df$mean_temperature_scaled
counts3 <- rbinom(samples, sample_sizes, plogis(linear_predictor))
counts3
linear_predictor
df$proportion_white_sneakers <- counts/sample_sizes
fm <- glm(proportion_white_sneakers ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'bionomial', data = df)
fm <- glm(proportion_white_sneakers ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'binomial', data = df)
df$counts_white_sneakers <- counts
fm <- glm(c(counts_white_sneakers, sample_sizes) ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'binomial', data = df)
fm <- glm(cbind(counts_white_sneakers, sample_sizes) ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'binomial', data = df)
summary(fm)
plgis(fm$coefficients)
plogis(fm$coefficients)
fm <- glm(cbind(counts_white_sneakers, sample_sizes-counts_white_sneakers) ~ mean_precipitation_scaled + mean_temperature_scaled,
weights = sample_sizes,
family = 'binomial', data = df)
summary(fm)
# Sample from a binomial with a probability dependent on the linear predictor, thus allow the parameter p to vary.
# Doing so, we scale variables and transform the linear predictor with the binomial link function
linear_predictor <- 1 - 0.1 *df$mean_precipitation - 0.2*df$mean_temperature
counts3 <- rbinom(samples, sample_sizes, plogis(linear_predictor))
cat(counts3)
set.seed(13)
samples <-  10
mean_temperature <- runif(10, 3, 15)
mean_precipitation <- runif(samples, 0, 200)
sample_sizes <- floor(runif(samples, 250, 500))
df <- data.frame(sample_sizes = sample_sizes,
mean_temperature = mean_temperature,
mean_precipitation = mean_precipitation )
df$mean_temperature_scaled = scale(df$mean_temperature)
df$mean_precipitation_scaled = scale(df$mean_precipitation)
counts1 <- round(runif(samples, min = 0, max = sample_sizes))
cat(counts1)
# Sample from a binomial with a fixed probability
counts2 <- rbinom(samples, sample_sizes, 0.3)
cat(counts2)
# Sample from a binomial with a probability dependent on the linear predictor, thus allow the parameter p to vary.
# Doing so, we scale variables and transform the linear predictor with the binomial link function
linear_predictor <- 1 - 0.2 *df$mean_precipitation_scaled - 0.2*df$mean_temperature_scaled
counts3 <- rbinom(samples, sample_sizes, plogis(linear_predictor))
cat(counts3)
# We use the last simulations for fitting the model.
df$proportion_white_sneakers <- counts3/sample_sizes
df$counts_white_sneakers <- counts3
fm <- glm(cbind(counts_white_sneakers, sample_sizes) ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'binomial', data = df)
summary(fm)
plogis(fm$coefficients)
fm <- glm(cbind(counts_white_sneakers, sample_sizes-counts_white_sneakers) ~ mean_precipitation_scaled + mean_temperature_scaled,
weights = sample_sizes,
family = 'binomial', data = df)
summary(fm)
plogis(fm$coefficients)
fm <- glm(cbind(counts_white_sneakers, sample_sizes) ~ mean_precipitation_scaled + mean_temperature_scaled, family = 'binomial', data = df)
summary(fm)
plogis(fm$coefficients)
install.packages('gauseR')
library(gauseR)
?gauseR
head(gauseR::gause_1936_AnE_f01)
summary(gauseR::gause_1936_AnE_f01)
?airquality
lm(airquality$Ozone ~  airquality$Wind)
summary(lm(airquality$Ozone ~  airquality$Wind))
summary(lm(airquality$Ozone ~  airquality$Temp))
plot(airquality$Ozone ~  airquality$Temp)
fm <- lm(airquality$Ozone ~  airquality$Temp)
lines(fm$fitted.values)
newdata = data.frame(Temp = seq(50, 100, 0.5))
preds = predict(fm, newdata = newdata, type = 'response')
newdat = data.frame(Temp = seq(50, 100, 0.5))
preds = predict(fm, newdata = newdat, type = 'response')
newdat = data.frame(Temp = sort(airquality$Temp))
preds = predict(fm, newdata = newdat, type = 'response')
lines(newpreds, col='red')
lines(preds, col='red')
lines(newdat$Temp, preds, col='red')
newdat = data.frame(Temp = airquality$Temp)
preds = predict(fm, newdata = newdat, type = 'response')
plot(airquality$Ozone ~  airquality$Temp)
lines(newdat$Temp, preds, col='red')
lines(newdat$Temp, preds, col='red', lwd=2)
?lm
library(Rpreles)
library(BayesianTools)
source("helpers.R")
setwd("~/PycharmProjects/physics_guided_nn/code")
setwd("~/PycharmProjects/physics_guided_nn/code")
#### install/load relevant packages ####
#devtools::install_github('MikkoPeltoniemi/Rpreles')
library(Rpreles)
library(BayesianTools)
source("helpers.R")
#set flags
make_nas_data = FALSE
ex_fit = FALSE
save_data = FALSE
if (make_nas_data){create_nas_data()}
if (ex_fit){example_fit()}
makesparse <- function(train){
ind <- seq(0,nrow(train), by=7)
tsmall <- train[ind,]
return(tsmall)
}
data_use = 'sparse'
scenario = 'exp2'
allsites <- read.csv("~/PycharmProjects/physics_guided_nn/data/allsites.csv")
allsites$date <- as.Date(allsites$date)
allsites$year <- format(allsites$date, format="%Y")
print(unique(allsites$year))
allsites$site <- gsub("[^a-zA-Z]", "", allsites$X)
if (scenario == 'exp2'){
allsites_train <- allsites[(allsites$site %in% c("sr","bz", "ly", "co")), ]
allsites_test <- allsites[((allsites$site == "h") & (allsites$year != 2004)), ]
}else if (scenario =='exp3'){
allsites_train <- allsites[(allsites$site %in% c("sr","bz", "ly", "co")), ]
allsites_train <- allsites_train[(allsites_train$year %in% c("2005", "2004")), ]
allsites_test <- allsites[((allsites$site == "h") & (allsites$year == "2008")), ]
}
if (data_use == 'sparse'){
allsites_train <- makesparse(allsites_train)
}
gpp_train <- matrix(NA, nrow=nrow(allsites_train), ncol=length(unique(allsites_train$site)))
gpp_test <- matrix(NA, nrow=nrow(allsites_test), ncol=length(unique(allsites_train$site)))
et_train <- matrix(NA, nrow=nrow(allsites_train), ncol=length(unique(allsites_train$site)))
et_test <- matrix(NA, nrow=nrow(allsites_test), ncol=length(unique(allsites_train$site)))
sw_train <- matrix(NA, nrow=nrow(allsites_train), ncol=length(unique(allsites_train$site)))
sw_test <- matrix(NA, nrow=nrow(allsites_test), ncol=length(unique(allsites_train$site)))
load(file = paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_CVfit_", data_use, "_", scenario, ".Rdata"))
i <- 1
for (s in unique(allsites_train$site)){
#load(file = paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_fit_", s, "_", data_use, ".Rdata"))
test_df <- allsites_test
gpp_train[,i] <- PRELES(PAR=allsites_train$PAR, TAir=allsites_train$Tair, VPD=allsites_train$VPD, Precip=allsites_train$Precip, CO2=allsites_train$CO2, fAPAR=allsites_train$fapar, DOY=allsites_train$DOY, p=CVfit[,i])$GPP
gpp_test[,i] <- PRELES(PAR=test_df$PAR, TAir=test_df$Tair, VPD=test_df$VPD, Precip=test_df$Precip, CO2=test_df$CO2, fAPAR=test_df$fapar, p=CVfit[,i])$GPP
et_train[,i] <- PRELES(PAR=allsites_train$PAR, TAir=allsites_train$Tair, VPD=allsites_train$VPD, Precip=allsites_train$Precip, CO2=allsites_train$CO2, fAPAR=allsites_train$fapar, DOY=allsites_train$DOY,p=CVfit[,i])$ET
et_test[,i] <- PRELES(PAR=test_df$PAR, TAir=test_df$Tair, VPD=test_df$VPD, Precip=test_df$Precip, CO2=test_df$CO2, fAPAR=test_df$fapar, p=CVfit[,i])$ET
sw_train[,i] <- PRELES(PAR=allsites_train$PAR, TAir=allsites_train$Tair, VPD=allsites_train$VPD, Precip=allsites_train$Precip, CO2=allsites_train$CO2, fAPAR=allsites_train$fapar, DOY=allsites_train$DOY, p=CVfit[,i])$SW
sw_test[,i] <- PRELES(PAR=test_df$PAR, TAir=test_df$Tair, VPD=test_df$VPD, Precip=test_df$Precip, CO2=test_df$CO2, fAPAR=test_df$fapar, p=CVfit[,i])$SW
i <- i+1
}
## Update data set with new calibrated Preles predictions ##
allsites_train$GPPp <- apply(gpp_train, 1, mean)
allsites_test$GPPp <- apply(gpp_test, 1, mean)
allsites_train$ETp <- apply(et_train, 1, mean)
allsites_test$ETp <- apply(et_test, 1, mean)
allsites_train$SWp <- apply(sw_train, 1, mean)
allsites_test$SWp <- apply(sw_test, 1, mean)
allsites_test$site == 'h'
length(allsites_test$site == 'h')
length(allsites_train$site == 'h')
View(allsites_train)
allsites_train$site == 'h'
allsites_train$site
allsitesF <- rbind(allsites_train, allsites_test)
write.csv(allsitesF, file=paste0("~/PycharmProjects/physics_guided_nn/data/allsitesF_", scenario,"_", data_use, ".csv"), row.names = FALSE)
# Plot posterior distributions
data_use='full'
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_CVfit", data_use, ".Rdata"))
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_CVfit_", data_use, ".Rdata"))
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_2009_", data_use, ".Rdata"))
fit[[1]]$chain[1]
for DEzs:
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Psinglesite_fit_2009_BayesPriors", scenario,"_", data_use,".pdf"), width=15, height=12)
data_use='full'
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_2009_", data_use, ".Rdata"))
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Psinglesite_fit_2009_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
fit[[1]]$chain[1]
ests <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
load("~/Projects/physics_guided_nn/data/parameterRanges.rdata") # parameter defaults/ranges
load("~/PycharmProjects/physics_guided_nn/data/parameterRanges.rdata") # parameter defaults/ranges
# par # note that "-999" is supposed to indiate NA!
pars <- par # unfortunate naming "par" replaced by "pars"
rm(par)
pars[pars=="-999"] <- NA
pars # note that some parameters are set without uncertainty (e.g. soildepth)
# jetzt neu: S[max]
#pars[pars$name=="S[max]", 4] <- 45 # was 30
#  S[max]: tick
pars[pars$name=="nu", 4] <- 10 # was 5
# select the parameters to be calibrated:
pars2tune <- c(5:11, 14:18, 31) # note that we omit 32, as it refers to ET
thispar <- pars$def
names(thispar) <- pars$name
data_use='full'
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_2009_", data_use, ".Rdata"))
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Psinglesite_fit_2009_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
fit[[1]]$chain[1]
ests <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
}
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_2009_", data_use, ".Rdata"))
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Psinglesite_fit_2009_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
fit[[1]]$chain[1]
ests <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
get_parameters <- function(){
load("~/PycharmProjects/physics_guided_nn/data/parameterRanges.rdata") # parameter defaults/ranges
# par # note that "-999" is supposed to indiate NA!
pars <- par # unfortunate naming "par" replaced by "pars"
rm(par)
pars[pars=="-999"] <- NA
pars # note that some parameters are set without uncertainty (e.g. soildepth)
# jetzt neu: S[max]
#pars[pars$name=="S[max]", 4] <- 45 # was 30
#  S[max]: tick
pars[pars$name=="nu", 4] <- 10 # was 5
# select the parameters to be calibrated:
pars2tune <- c(5:11, 14:18, 31) # note that we omit 32, as it refers to ET
thispar <- pars$def
names(thispar) <- pars$name
return(pars, pars2tune, thispar)
}
pars, pars2tune, thispar <- get_parameters()
pars<- get_parameters()
load(paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_fit_b_", data_use, ".Rdata"))
load(paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_fit_bz_exp3", data_use, ".Rdata"))
load(paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_fit_bz_exp3_", data_use, ".Rdata"))
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Pmultisite_fit_b_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
fit[[1]]$chain[1]
ests <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
[2009,2010,2011,2012]
data_use='full'
years <- c(2009,2010,2011,2012)
ests <- NULL
for (year in years){ # loop over years
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_", year,"_", data_use, ".Rdata"))
fit[[1]]$chain[1]
est <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
ests <- rbind(ests, est)
}
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/Psinglesite_fit_2009_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
data_use='full'
sites <- c('bz','co','ly','sr')
ests <- NULL
for (site in sites){ # loop over years
load(paste0("~/PycharmProjects/physics_guided_nn/data/Pmultisite_fit_", site,"_exp3_", data_use, ".Rdata"))
fit[[1]]$chain[1]
est <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
ests <- rbind(ests, est)
}
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/calibration/Pmultisite_fit_BayesPriors_exp3_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
data_use='full'
years <- c(2009,2010,2011,2012)
ests <- NULL
for (year in years){ # loop over years
load(paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_", year,"_", data_use, ".Rdata"))
fit[[1]]$chain[1]
est <- rbind(fit[[1]]$Z, fit[[2]]$Z, fit[[3]]$Z)
ests <- rbind(ests, est)
}
pdf(file=paste0("~/PycharmProjects/physics_guided_nn/plots/calibration/Psinglesite_fit_BayesPriors_", data_use,".pdf"), width=15, height=12)
par(mfrow=c(4, 4), mar=c(3,3,3,1))
for (i in 1:ncol(fit[[1]]$X)){ # loop over parameters fitted
plot(density(ests[,i], from=min(ests[,i]), to=max(ests[,i])), main=pars[pars2tune[i],1], las=1)
abline(v=pars[pars2tune[i], 3:4], col="red")
}
dev.off()
year <- 2009
data_use <- 'sparse'
load(file = paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_", year,"_", data_use, ".Rdata"))
## Fit PRELES to site data
setwd("~/PycharmProjects/physics_guided_nn/code")
#### install/load relevant packages ####
#devtools::install_github('MikkoPeltoniemi/Rpreles')
library(Rpreles)
library(BayesianTools)
source("helpers.R")
#set flags
make_nas_data = FALSE
ex_fit = FALSE
if (make_nas_data){create_nas_data()}
if (ex_fit){example_fit()}
makesparse <- function(train){
ind <- seq(0,nrow(train), by=7)
tsmall <- train[ind,]
return(tsmall)
}
load_pars <- function(){
load("~/PycharmProjects/physics_guided_nn/data/parameterRanges.rdata") # parameter defaults/ranges
# par # note that "-999" is supposed to indiate NA!
pars <- par # unfortunate naming "par" replaced by "pars"
rm(par)
pars[pars=="-999"] <- NA
pars # note that some parameters are set without uncertainty (e.g. soildepth)
#pars[pars$name=="S[max]", 4] <- 45
pars[pars$name=="nu", 4] <- 10 # was 5
return(pars)
}
singlesite_calibration <- function(data_use, save_data=FALSE){
pars <- load_pars()
# select the parameters to be calibrated:
pars2tune <- c(5:11, 14:18, 31) # note that we omit 32, as it refers to ET
thispar <- pars$def
names(thispar) <- pars$name
hyytiala <- read.csv("~/PycharmProjects/physics_guided_nn/data/hyytiala.csv")
hyytiala$date <- as.Date(hyytiala$date)
hyytiala$year <- format(hyytiala$date, format="%Y")
hyytiala_train <- hyytiala[!(hyytiala$year %in% c("2008", "2007", "2005", "2004")), ]
hyytiala_test <- hyytiala[hyytiala$year == "2008", ]
attach(hyytiala_train)
if (data_use == 'sparse'){
hyytiala_train <- makesparse(hyytiala_train)
}
CVfit <- matrix(NA, nrow=nrow(pars), ncol = length(unique(hyytiala_train$year)))
i <- 1
for (year in unique(hyytiala_train$year)){
df <- hyytiala_train[hyytiala_train$year != year,]
ell <- function(pars, data=df){
# pars is a vector the same length as pars2tune
thispar[pars2tune] <- pars
# likelihood function, first shot: normal density
with(data, sum(dnorm(df$GPP, mean=PRELES(PAR=df$PAR, TAir=df$Tair, VPD=df$VPD, Precip=df$Precip, CO2=df$CO2, fAPAR=df$fapar , p=thispar)$GPP, sd=thispar[31], log=T)))
}
priors <- createUniformPrior(lower=pars$min[pars2tune], upper=pars$max[pars2tune], best=pars$def[pars2tune])
setup <- createBayesianSetup(likelihood=ell, prior=priors, parallel=T)
settings <- list(iterations=50000, adapt=T, nrChains=3, parallel=T) # runs 3 chains in parallel for each chain ...
# run:
fit <- runMCMC(bayesianSetup = setup, settings = settings, sampler = "DREAMzs")
save(fit, file = paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_fit_", year,"_", data_use, ".Rdata"))
pars_fit <- pars
pars_fit$def[pars2tune] <- MAP(fit)$parametersMAP
CVfit[,i] <- pars_fit$def
i = i+1
}
save(CVfit, file = paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_CVfit_", data_use, ".Rdata"))
write.csv(CVfit, file=paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_CVfit_", data_use, ".csv"))
gpp_train <- matrix(NA, nrow=nrow(hyytiala_train), ncol=length(unique(hyytiala_train$year)))
gpp_test <- matrix(NA, nrow=nrow(hyytiala_test), ncol=length(unique(hyytiala_train$year)))
et_train <- matrix(NA, nrow=nrow(hyytiala_train), ncol=length(unique(hyytiala_train$year)))
et_test <- matrix(NA, nrow=nrow(hyytiala_test), ncol=length(unique(hyytiala_train$year)))
sw_train <- matrix(NA, nrow=nrow(hyytiala_train), ncol=length(unique(hyytiala_train$year)))
sw_test <- matrix(NA, nrow=nrow(hyytiala_test), ncol=length(unique(hyytiala_train$year)))
load(file = paste0("~/PycharmProjects/physics_guided_nn/data/Psinglesite_CVfit_", data_use, ".Rdata"))
for (year in 1: length(unique(hyytiala_train$year))){
gpp_train[,i] <- PRELES(PAR=hyytiala_train$PAR, TAir=hyytiala_train$Tair, VPD=hyytiala_train$VPD, Precip=hyytiala_train$Precip, CO2=hyytiala_train$CO2, fAPAR=hyytiala_train$fapar, p=CVfit[,i])$GPP
gpp_test[,i] <- PRELES(PAR=hyytiala_test$PAR, TAir=hyytiala_test$Tair, VPD=hyytiala_test$VPD, Precip=hyytiala_test$Precip, CO2=hyytiala_test$CO2, fAPAR=hyytiala_test$fapar, p=CVfit[,i])$GPP
et_train[,i] <- PRELES(PAR=hyytiala_train$PAR, TAir=hyytiala_train$Tair, VPD=hyytiala_train$VPD, Precip=hyytiala_train$Precip, CO2=hyytiala_train$CO2, fAPAR=hyytiala_train$fapar, p=CVfit[,i])$ET
et_test[,i] <- PRELES(PAR=hyytiala_test$PAR, TAir=hyytiala_test$Tair, VPD=hyytiala_test$VPD, Precip=hyytiala_test$Precip, CO2=hyytiala_test$CO2, fAPAR=hyytiala_test$fapar, p=CVfit[,i])$ET
sw_train[,i] <- PRELES(PAR=hyytiala_train$PAR, TAir=hyytiala_train$Tair, VPD=hyytiala_train$VPD, Precip=hyytiala_train$Precip, CO2=hyytiala_train$CO2, fAPAR=hyytiala_train$fapar, p=CVfit[,i])$SW
sw_test[,i] <- PRELES(PAR=hyytiala_test$PAR, TAir=hyytiala_test$Tair, VPD=hyytiala_test$VPD, Precip=hyytiala_test$Precip, CO2=hyytiala_test$CO2, fAPAR=hyytiala_test$fapar, p=CVfit[,i])$SW
}
## Update data set with new calibrated Preles predictions ##
hyytiala_train$GPPp <- apply(gpp_train, 1, mean)
hyytiala_test$GPPp <- apply(gpp_test, 1, mean)
hyytiala_train$ETp <- apply(et_train, 1, mean)
hyytiala_test$ETp <- apply(et_test, 1, mean)
hyytiala_train$SWp <- apply(sw_train, 1, mean)
hyytiala_test$SWp <- apply(sw_test, 1, mean)
if (save_data){
hyytialaF <- rbind(hyytiala_train, hyytiala_test)
write.csv(hyytialaF, file=paste0("~/PycharmProjects/physics_guided_nn/data/hyytialaF_", data_use, ".csv"), row.names = FALSE)
## Generate files for prediction results ##
save(gpp_train, file = "~/PycharmProjects/physics_guided_nn/data/GPPp_singlesite_train.Rdata")
save(gpp_test, file = "~/PycharmProjects/physics_guided_nn/data/GPPp_singlesite_test.Rdata")
}
GPP_train <- apply(gpp_train, 1, mean)
GPP_test <- apply(gpp_test, 1, mean)
GPP_train_std <- apply(gpp_train, 1, sd)
GPP_test_std <- apply(gpp_test, 1, sd)
mae <- function(yhat){
mae <- sum(abs(hyytiala_test$GPP - yhat))/length(yhat)
return(mae)
}
rmse <- function(yhat){
rmse <- sqrt(sum((hyytiala_test$GPP - yhat)^2)/length(yhat))
return(rmse)
}
perfpormance_preles_full <- matrix(NA, nrow=4, ncol=2)
perfpormance_preles_full[,1] <- apply(gpp_test, 2, rmse)
perfpormance_preles_full[,2] <- apply(gpp_test, 2, mae)
write.csv(perfpormance_preles_full, file=paste0("~/PycharmProjects/physics_guided_nn/results_final/preles_eval_", data_use, "_performance.csv"))
write.csv(gpp_test, file=paste0("~/PycharmProjects/physics_guided_nn/results_final/preles_eval_preds_test_", data_use, ".csv"))
}
singlesite_calibration(data_use = 'full')
